{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the Data for ML Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('telecom_churn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7043, 21)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerID</th>\n",
       "      <th>gender</th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>Partner</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>tenure</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>MultipleLines</th>\n",
       "      <th>InternetService</th>\n",
       "      <th>OnlineSecurity</th>\n",
       "      <th>...</th>\n",
       "      <th>DeviceProtection</th>\n",
       "      <th>TechSupport</th>\n",
       "      <th>StreamingTV</th>\n",
       "      <th>StreamingMovies</th>\n",
       "      <th>Contract</th>\n",
       "      <th>PaperlessBilling</th>\n",
       "      <th>PaymentMethod</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7590-VHVEG</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>29.85</td>\n",
       "      <td>29.85</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5575-GNVDE</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>34</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>56.95</td>\n",
       "      <td>1889.50</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3668-QPYBK</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>53.85</td>\n",
       "      <td>108.15</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7795-CFOCW</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>45</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Bank transfer (automatic)</td>\n",
       "      <td>42.30</td>\n",
       "      <td>1840.75</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9237-HQITU</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>70.70</td>\n",
       "      <td>151.65</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   customerID  gender  SeniorCitizen Partner Dependents  tenure PhoneService  \\\n",
       "0  7590-VHVEG  Female              0     Yes         No       1           No   \n",
       "1  5575-GNVDE    Male              0      No         No      34          Yes   \n",
       "2  3668-QPYBK    Male              0      No         No       2          Yes   \n",
       "3  7795-CFOCW    Male              0      No         No      45           No   \n",
       "4  9237-HQITU  Female              0      No         No       2          Yes   \n",
       "\n",
       "      MultipleLines InternetService OnlineSecurity  ... DeviceProtection  \\\n",
       "0  No phone service             DSL             No  ...               No   \n",
       "1                No             DSL            Yes  ...              Yes   \n",
       "2                No             DSL            Yes  ...               No   \n",
       "3  No phone service             DSL            Yes  ...              Yes   \n",
       "4                No     Fiber optic             No  ...               No   \n",
       "\n",
       "  TechSupport StreamingTV StreamingMovies        Contract PaperlessBilling  \\\n",
       "0          No          No              No  Month-to-month              Yes   \n",
       "1          No          No              No        One year               No   \n",
       "2          No          No              No  Month-to-month              Yes   \n",
       "3         Yes          No              No        One year               No   \n",
       "4          No          No              No  Month-to-month              Yes   \n",
       "\n",
       "               PaymentMethod MonthlyCharges  TotalCharges  Churn  \n",
       "0           Electronic check          29.85         29.85     No  \n",
       "1               Mailed check          56.95       1889.50     No  \n",
       "2               Mailed check          53.85        108.15    Yes  \n",
       "3  Bank transfer (automatic)          42.30       1840.75     No  \n",
       "4           Electronic check          70.70        151.65    Yes  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting Display options to ensure feature name visibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns',None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Warning Suppression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How many rows have missing ID ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['customerID'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop ID Feature from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(['customerID'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label the Churn feature to 1/0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df['Churn'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target']=np.where(df['Churn']==\"Yes\",1,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop the Churn feature to retain only Target "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(['Churn'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Target and Independent Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=df[['target']]\n",
    "X=df.drop(['target'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the Churn Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split features into Numerical and Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num=X.select_dtypes(include=\"number\")\n",
    "char=X.select_dtypes(include=\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check whether SeniorCitizon feaure is an indicator\n",
    "num.SeniorCitizen.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "char.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropping the indicator features from num to build a separate DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind=num[['SeniorCitizen']]\n",
    "num=num.drop(['SeniorCitizen'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outlier Analysis of Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num.describe(percentiles=[0.01,0.05,0.10,0.25,0.50,0.75,0.85,0.9,0.99])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capping and Flooring of outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outlier_cap(x):\n",
    "    x=x.clip(lower=x.quantile(0.01))\n",
    "    x=x.clip(upper=x.quantile(0.99))\n",
    "    return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num=num.apply(lambda x : outlier_cap(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num.describe(percentiles=[0.01,0.05,0.10,0.25,0.50,0.75,0.85,0.9,0.99])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing Value Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num.isnull().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Since the data does not contain any missing values Imputation Processes are not required"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection - Numerical Features "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 : Remove Features with 0 Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "varselector= VarianceThreshold(threshold=0)\n",
    "varselector.fit_transform(num)\n",
    "# Get columns to keep and create new dataframe with those only\n",
    "cols = varselector.get_support(indices=True)\n",
    "num_1 = num.iloc[:,cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_1.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 - Bi Variate Analysis (Feature Discretization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "discrete=KBinsDiscretizer(n_bins=10,encode='ordinal', strategy='quantile')\n",
    "num_binned=pd.DataFrame(discrete.fit_transform(num_1),index=num_1.index, columns=num_1.columns).add_suffix('_Rank')\n",
    "num_binned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Check if the features show a slope at all\n",
    "#If they do, then do you see some deciles below the population average and some higher than population average?\n",
    "#If that is the case then the slope will be strong\n",
    "#Conclusion: A strong slope is indicative of the features' ability to discriminate the event from non event\n",
    "#            making it a good predictor\n",
    "\n",
    "#percentage_income_goesinto_intallments=Insallment/annual_inc (Derived Variables/Feature Engineering)\n",
    "\n",
    "X_bin_combined=pd.concat([Y,num_binned],axis=1,join='inner')\n",
    "\n",
    "from numpy import mean\n",
    "for col in (num_binned.columns):\n",
    "    plt.figure()\n",
    "    sns.barplot(x=col, y=\"target\",data=X_bin_combined, estimator=mean )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All features from num_2 will get selected due to good discrimination\n",
    "select_features_df_num=num_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection - Categorical Features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "char.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 - Bi Variate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "X_char_merged=pd.concat([Y,char],axis=1,join='inner')\n",
    "\n",
    "from numpy import mean\n",
    "for col in (char.columns):\n",
    "    plt.figure()\n",
    "    sns.barplot(x=col, y=\"target\",data=X_char_merged, estimator=mean )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "char=char.drop(['gender','PhoneService','MultipleLines'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy features with n-1 levels\n",
    "X_char_dum = pd.get_dummies(char, drop_first = True)\n",
    "X_char_dum.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 - Select K Best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select K Best for Categorical Features\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "selector = SelectKBest(chi2, k=20)\n",
    "selector.fit_transform(X_char_dum, Y)\n",
    "# Get columns to keep and create new dataframe with those only\n",
    "cols = selector.get_support(indices=True)\n",
    "select_features_df_char = X_char_dum.iloc[:,cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "select_features_df_char.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection - Numerical Indicator Features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_ind_merged=pd.concat([Y,ind],axis=1,join='inner')\n",
    "from numpy import mean\n",
    "for col in (ind.columns):\n",
    "    plt.figure()\n",
    "    sns.barplot(x=col, y=\"target\",data=X_ind_merged, estimator=mean )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_features_df_ind=ind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Master Feature Set for Model Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all=pd.concat([select_features_df_char,select_features_df_num,select_features_df_ind],axis=1,join=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Y['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test=train_test_split(X_all, Y, test_size=0.3, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of Training Data\",X_train.shape)\n",
    "print(\"Shape of Testing Data\",X_test.shape)\n",
    "print(\"Response Rate in Training Data\",y_train.mean())\n",
    "print(\"Response Rate in Testing Data\",y_test.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non Linearity in feature relationships are observed which makes tree methods a good choice\n",
    "# There are few options to consider among tree methods\n",
    "# White Box (Completely Explainable Set of Rules) - Decision Tree\n",
    "# Ensemble Methods - Random Forest (With Bagging)\n",
    "# Ensemble Methods - GBM/XGBoost (Boosting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg=LogisticRegression(random_state=0)\n",
    "logreg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff_df=pd.DataFrame(X_all.columns)\n",
    "coeff_df.columns=['features']\n",
    "coeff_df[\"Coefficient Estimate\"] = pd.Series(logreg.coef_[0])\n",
    "coeff_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building a Decision Tree Model\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtree=DecisionTreeClassifier(criterion='gini',random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(44)\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_dist = {'max_depth': [3, 5, 6, 7], 'min_samples_split': [50, 100, 150, 200, 250] }\n",
    "tree_grid = GridSearchCV(dtree, cv = 10, param_grid=param_dist,n_jobs = 3)\n",
    "tree_grid.fit(X_train,y_train) \n",
    "print('Best Parameters using grid search: \\n', tree_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree=DecisionTreeClassifier(criterion='gini',random_state=0,max_depth=6,min_samples_split=50)\n",
    "dtree.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "import pydotplus\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=[50,10])\n",
    "tree.plot_tree(dtree,filled=True,fontsize=15,rounded=True,feature_names=X_all.columns)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building a Random Forest Model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf=RandomForestClassifier(criterion='gini',random_state=0,max_depth=6,min_samples_split=50)\n",
    "rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "feature_importances=pd.DataFrame(rf.feature_importances_,\n",
    "                                 index=X_train.columns,\n",
    "                                 columns=['importance']).sort_values('importance',ascending=False)\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building a Gradient Boosting Model\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbm=GradientBoostingClassifier(criterion='mse',random_state=0,max_depth=6,min_samples_split=50)\n",
    "gbm.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "feature_importances=pd.DataFrame(gbm.feature_importances_,\n",
    "                                 index=X_train.columns,\n",
    "                                 columns=['importance']).sort_values('importance',ascending=False)\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_learners = [\n",
    "                        ('rf', RandomForestClassifier(criterion='gini',random_state=0,max_depth=6,min_samples_split=50)),\n",
    "                        ('gbm', GradientBoostingClassifier(criterion='mse',random_state=0,max_depth=6,min_samples_split=50))  \n",
    "                       ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "clf = StackingClassifier(estimators=base_learners, final_estimator=LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation\n",
    "y_pred_logreg=logreg.predict(X_test)\n",
    "y_pred_tree=dtree.predict(X_test)\n",
    "y_pred_rf=rf.predict(X_test)\n",
    "y_pred_gbm=gbm.predict(X_test)\n",
    "y_pred_stacking=clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred_logreg))\n",
    "print(\"Precision\",metrics.precision_score(y_test,y_pred_logreg))\n",
    "print(\"Recall\",metrics.recall_score(y_test,y_pred_logreg))\n",
    "print(\"f1_score\",metrics.f1_score(y_test,y_pred_logreg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.plot_confusion_matrix(logreg,X_all,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred_tree))\n",
    "print(\"Precision\",metrics.precision_score(y_test,y_pred_tree))\n",
    "print(\"Recall\",metrics.recall_score(y_test,y_pred_tree))\n",
    "print(\"f1_score\",metrics.f1_score(y_test,y_pred_tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.plot_confusion_matrix(dtree,X_all,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred_rf))\n",
    "print(\"Precision\",metrics.precision_score(y_test,y_pred_rf))\n",
    "print(\"Recall\",metrics.recall_score(y_test,y_pred_rf))\n",
    "print(\"f1_score\",metrics.f1_score(y_test,y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.plot_confusion_matrix(rf,X_all,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred_gbm))\n",
    "print(\"Precision\",metrics.precision_score(y_test,y_pred_gbm))\n",
    "print(\"Recall\",metrics.recall_score(y_test,y_pred_gbm))\n",
    "print(\"f1_score\",metrics.f1_score(y_test,y_pred_gbm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metrics.plot_confusion_matrix(gbm,X_all,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred_stacking))\n",
    "print(\"Precision\",metrics.precision_score(y_test,y_pred_stacking))\n",
    "print(\"Recall\",metrics.recall_score(y_test,y_pred_stacking))\n",
    "print(\"f1_score\",metrics.f1_score(y_test,y_pred_stacking))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.plot_confusion_matrix(clf,X_all,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lorenz Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decsion Tree Lorenz Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_pred_prob = logreg.predict_proba(X_all)[:, 1]\n",
    "df['pred_prob_logreg']=pd.DataFrame(y_pred_prob)\n",
    "df['P_Rank_logreg']=pd.qcut(df['pred_prob_logreg'].rank(method='first').values,10,duplicates='drop').codes+1\n",
    "rank_df_actuals=df.groupby('P_Rank_logreg')['target'].agg(['count','mean'])\n",
    "rank_df_predicted=df.groupby('P_Rank_logreg')['pred_prob_logreg'].agg(['mean'])\n",
    "rank_df_actuals=pd.DataFrame(rank_df_actuals)\n",
    "\n",
    "rank_df_actuals.rename(columns={'mean':'Actutal_event_rate'},inplace=True)\n",
    "rank_df_predicted=pd.DataFrame(rank_df_predicted)\n",
    "rank_df_predicted.rename(columns={'mean':'Predicted_event_rate'},inplace=True)\n",
    "rank_df=pd.concat([rank_df_actuals,rank_df_predicted],axis=1,join=\"inner\")\n",
    "\n",
    "sorted_rank_df=rank_df.sort_values(by='P_Rank_logreg',ascending=False)\n",
    "sorted_rank_df['N_events']=rank_df['count']*rank_df['Actutal_event_rate']\n",
    "sorted_rank_df['cum_events']=sorted_rank_df['N_events'].cumsum()\n",
    "sorted_rank_df['event_cap']=sorted_rank_df['N_events']/max(sorted_rank_df['N_events'].cumsum())\n",
    "sorted_rank_df['cum_event_cap']=sorted_rank_df['event_cap'].cumsum()\n",
    "\n",
    "sorted_rank_df['N_non_events']=sorted_rank_df['count']-sorted_rank_df['N_events']\n",
    "sorted_rank_df['cum_non_events']=sorted_rank_df['N_non_events'].cumsum()\n",
    "sorted_rank_df['non_event_cap']=sorted_rank_df['N_non_events']/max(sorted_rank_df['N_non_events'].cumsum())\n",
    "sorted_rank_df['cum_non_event_cap']=sorted_rank_df['non_event_cap'].cumsum()\n",
    "\n",
    "sorted_rank_df['KS']=round((sorted_rank_df['cum_event_cap']-sorted_rank_df['cum_non_event_cap']),4)\n",
    "\n",
    "sorted_rank_df['random_cap']=sorted_rank_df['count']/max(sorted_rank_df['count'].cumsum())\n",
    "sorted_rank_df['cum_random_cap']=sorted_rank_df['random_cap'].cumsum()\n",
    "sorted_reindexed=sorted_rank_df.reset_index()\n",
    "sorted_reindexed['Decile']=sorted_reindexed.index+1\n",
    "sorted_reindexed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ax = sns.lineplot( x=\"Decile\", y=\"Actutal_event_rate\", data=sorted_reindexed,color='red')\n",
    "ax = sns.lineplot( x=\"Decile\", y=\"Predicted_event_rate\", data=sorted_reindexed,color='grey')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob = dtree.predict_proba(X_all)[:, 1]\n",
    "df['pred_prob_dtree']=pd.DataFrame(y_pred_prob)\n",
    "df['P_Rank_tree']=pd.qcut(df['pred_prob_dtree'].rank(method='first').values,10,duplicates='drop').codes+1\n",
    "rank_df_actuals=df.groupby('P_Rank_tree')['target'].agg(['count','mean'])\n",
    "rank_df_predicted=df.groupby('P_Rank_tree')['pred_prob_dtree'].agg(['mean'])\n",
    "rank_df_actuals=pd.DataFrame(rank_df_actuals)\n",
    "\n",
    "rank_df_actuals.rename(columns={'mean':'Actutal_event_rate'},inplace=True)\n",
    "rank_df_predicted=pd.DataFrame(rank_df_predicted)\n",
    "rank_df_predicted.rename(columns={'mean':'Predicted_event_rate'},inplace=True)\n",
    "rank_df=pd.concat([rank_df_actuals,rank_df_predicted],axis=1,join=\"inner\")\n",
    "\n",
    "sorted_rank_df=rank_df.sort_values(by='P_Rank_tree',ascending=False)\n",
    "sorted_rank_df['N_events']=rank_df['count']*rank_df['Actutal_event_rate']\n",
    "sorted_rank_df['cum_events']=sorted_rank_df['N_events'].cumsum()\n",
    "sorted_rank_df['event_cap']=sorted_rank_df['N_events']/max(sorted_rank_df['N_events'].cumsum())\n",
    "sorted_rank_df['cum_event_cap']=sorted_rank_df['event_cap'].cumsum()\n",
    "\n",
    "sorted_rank_df['N_non_events']=sorted_rank_df['count']-sorted_rank_df['N_events']\n",
    "sorted_rank_df['cum_non_events']=sorted_rank_df['N_non_events'].cumsum()\n",
    "sorted_rank_df['non_event_cap']=sorted_rank_df['N_non_events']/max(sorted_rank_df['N_non_events'].cumsum())\n",
    "sorted_rank_df['cum_non_event_cap']=sorted_rank_df['non_event_cap'].cumsum()\n",
    "\n",
    "sorted_rank_df['KS']=round((sorted_rank_df['cum_event_cap']-sorted_rank_df['cum_non_event_cap']),4)\n",
    "\n",
    "sorted_rank_df['random_cap']=sorted_rank_df['count']/max(sorted_rank_df['count'].cumsum())\n",
    "sorted_rank_df['cum_random_cap']=sorted_rank_df['random_cap'].cumsum()\n",
    "sorted_reindexed=sorted_rank_df.reset_index()\n",
    "sorted_reindexed['Decile']=sorted_reindexed.index+1\n",
    "sorted_reindexed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.lineplot( x=\"Decile\", y=\"Actutal_event_rate\", data=sorted_reindexed,color='red')\n",
    "ax = sns.lineplot( x=\"Decile\", y=\"Predicted_event_rate\", data=sorted_reindexed,color='grey')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Lorenz Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred_prob = rf.predict_proba(X_all)[:, 1]\n",
    "df['pred_prob_rf']=pd.DataFrame(y_pred_prob)\n",
    "df['P_Rank_rf']=pd.qcut(df['pred_prob_rf'].rank(method='first').values,10,duplicates='drop').codes+1\n",
    "rank_df_actuals=df.groupby('P_Rank_rf')['target'].agg(['count','mean'])\n",
    "rank_df_predicted=df.groupby('P_Rank_rf')['pred_prob_rf'].agg(['mean'])\n",
    "rank_df_actuals=pd.DataFrame(rank_df_actuals)\n",
    "\n",
    "rank_df_actuals.rename(columns={'mean':'Actutal_event_rate'},inplace=True)\n",
    "rank_df_predicted=pd.DataFrame(rank_df_predicted)\n",
    "rank_df_predicted.rename(columns={'mean':'Predicted_event_rate'},inplace=True)\n",
    "rank_df=pd.concat([rank_df_actuals,rank_df_predicted],axis=1,join=\"inner\")\n",
    "\n",
    "sorted_rank_df=rank_df.sort_values(by='P_Rank_rf',ascending=False)\n",
    "sorted_rank_df['N_events']=rank_df['count']*rank_df['Actutal_event_rate']\n",
    "sorted_rank_df['cum_events']=sorted_rank_df['N_events'].cumsum()\n",
    "sorted_rank_df['event_cap']=sorted_rank_df['N_events']/max(sorted_rank_df['N_events'].cumsum())\n",
    "sorted_rank_df['cum_event_cap']=sorted_rank_df['event_cap'].cumsum()\n",
    "\n",
    "sorted_rank_df['N_non_events']=sorted_rank_df['count']-sorted_rank_df['N_events']\n",
    "sorted_rank_df['cum_non_events']=sorted_rank_df['N_non_events'].cumsum()\n",
    "sorted_rank_df['non_event_cap']=sorted_rank_df['N_non_events']/max(sorted_rank_df['N_non_events'].cumsum())\n",
    "sorted_rank_df['cum_non_event_cap']=sorted_rank_df['non_event_cap'].cumsum()\n",
    "\n",
    "sorted_rank_df['KS']=round((sorted_rank_df['cum_event_cap']-sorted_rank_df['cum_non_event_cap']),4)\n",
    "\n",
    "sorted_rank_df['random_cap']=sorted_rank_df['count']/max(sorted_rank_df['count'].cumsum())\n",
    "sorted_rank_df['cum_random_cap']=sorted_rank_df['random_cap'].cumsum()\n",
    "sorted_reindexed=sorted_rank_df.reset_index()\n",
    "sorted_reindexed['Decile']=sorted_reindexed.index+1\n",
    "sorted_reindexed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ax = sns.lineplot( x=\"Decile\", y=\"Actutal_event_rate\", data=sorted_reindexed,color='red')\n",
    "ax = sns.lineplot( x=\"Decile\", y=\"Predicted_event_rate\", data=sorted_reindexed,color='grey')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred_prob = gbm.predict_proba(X_all)[:, 1]\n",
    "df['pred_prob_gbm']=pd.DataFrame(y_pred_prob)\n",
    "df['P_Rank_GBM']=pd.qcut(df['pred_prob_gbm'].rank(method='first').values,10,duplicates='drop').codes+1\n",
    "rank_df_actuals=df.groupby('P_Rank_GBM')['target'].agg(['count','mean'])\n",
    "rank_df_predicted=df.groupby('P_Rank_GBM')['pred_prob_gbm'].agg(['mean'])\n",
    "rank_df_actuals=pd.DataFrame(rank_df_actuals)\n",
    "\n",
    "rank_df_actuals.rename(columns={'mean':'Actutal_event_rate'},inplace=True)\n",
    "rank_df_predicted=pd.DataFrame(rank_df_predicted)\n",
    "rank_df_predicted.rename(columns={'mean':'Predicted_event_rate'},inplace=True)\n",
    "rank_df=pd.concat([rank_df_actuals,rank_df_predicted],axis=1,join=\"inner\")\n",
    "\n",
    "sorted_rank_df=rank_df.sort_values(by='P_Rank_GBM',ascending=False)\n",
    "sorted_rank_df['N_events']=rank_df['count']*rank_df['Actutal_event_rate']\n",
    "sorted_rank_df['cum_events']=sorted_rank_df['N_events'].cumsum()\n",
    "sorted_rank_df['event_cap']=sorted_rank_df['N_events']/max(sorted_rank_df['N_events'].cumsum())\n",
    "sorted_rank_df['cum_event_cap']=sorted_rank_df['event_cap'].cumsum()\n",
    "\n",
    "sorted_rank_df['N_non_events']=sorted_rank_df['count']-sorted_rank_df['N_events']\n",
    "sorted_rank_df['cum_non_events']=sorted_rank_df['N_non_events'].cumsum()\n",
    "sorted_rank_df['non_event_cap']=sorted_rank_df['N_non_events']/max(sorted_rank_df['N_non_events'].cumsum())\n",
    "sorted_rank_df['cum_non_event_cap']=sorted_rank_df['non_event_cap'].cumsum()\n",
    "\n",
    "sorted_rank_df['KS']=round((sorted_rank_df['cum_event_cap']-sorted_rank_df['cum_non_event_cap']),4)\n",
    "\n",
    "sorted_rank_df['random_cap']=sorted_rank_df['count']/max(sorted_rank_df['count'].cumsum())\n",
    "sorted_rank_df['cum_random_cap']=sorted_rank_df['random_cap'].cumsum()\n",
    "sorted_reindexed=sorted_rank_df.reset_index()\n",
    "sorted_reindexed['Decile']=sorted_reindexed.index+1\n",
    "sorted_reindexed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ax = sns.lineplot( x=\"Decile\", y=\"Actutal_event_rate\", data=sorted_reindexed,color='red')\n",
    "ax = sns.lineplot( x=\"Decile\", y=\"Predicted_event_rate\", data=sorted_reindexed,color='grey')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob = clf.predict_proba(X_all)[:, 1]\n",
    "df['pred_prob_stacking']=pd.DataFrame(y_pred_prob)\n",
    "df['P_Rank_stacking']=pd.qcut(df['pred_prob_stacking'].rank(method='first').values,10,duplicates='drop').codes+1\n",
    "rank_df_actuals=df.groupby('P_Rank_stacking')['target'].agg(['count','mean'])\n",
    "rank_df_predicted=df.groupby('P_Rank_stacking')['pred_prob_stacking'].agg(['mean'])\n",
    "rank_df_actuals=pd.DataFrame(rank_df_actuals)\n",
    "\n",
    "rank_df_actuals.rename(columns={'mean':'Actutal_event_rate'},inplace=True)\n",
    "rank_df_predicted=pd.DataFrame(rank_df_predicted)\n",
    "rank_df_predicted.rename(columns={'mean':'Predicted_event_rate'},inplace=True)\n",
    "rank_df=pd.concat([rank_df_actuals,rank_df_predicted],axis=1,join=\"inner\")\n",
    "\n",
    "sorted_rank_df=rank_df.sort_values(by='P_Rank_stacking',ascending=False)\n",
    "sorted_rank_df['N_events']=rank_df['count']*rank_df['Actutal_event_rate']\n",
    "sorted_rank_df['cum_events']=sorted_rank_df['N_events'].cumsum()\n",
    "sorted_rank_df['event_cap']=sorted_rank_df['N_events']/max(sorted_rank_df['N_events'].cumsum())\n",
    "sorted_rank_df['cum_event_cap']=sorted_rank_df['event_cap'].cumsum()\n",
    "\n",
    "sorted_rank_df['N_non_events']=sorted_rank_df['count']-sorted_rank_df['N_events']\n",
    "sorted_rank_df['cum_non_events']=sorted_rank_df['N_non_events'].cumsum()\n",
    "sorted_rank_df['non_event_cap']=sorted_rank_df['N_non_events']/max(sorted_rank_df['N_non_events'].cumsum())\n",
    "sorted_rank_df['cum_non_event_cap']=sorted_rank_df['non_event_cap'].cumsum()\n",
    "\n",
    "sorted_rank_df['KS']=round((sorted_rank_df['cum_event_cap']-sorted_rank_df['cum_non_event_cap']),4)\n",
    "\n",
    "sorted_rank_df['random_cap']=sorted_rank_df['count']/max(sorted_rank_df['count'].cumsum())\n",
    "sorted_rank_df['cum_random_cap']=sorted_rank_df['random_cap'].cumsum()\n",
    "sorted_reindexed=sorted_rank_df.reset_index()\n",
    "sorted_reindexed['Decile']=sorted_reindexed.index+1\n",
    "sorted_reindexed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project Conclusion :- \n",
    "# The GBM Model has performed the best and will be used for Customer targeting with Loan offers\n",
    "# Since Monthly Income and Existing EMI are the most important features for the GBM model\n",
    "# We will build a Business Value Metric based on Existing EMI/Monthly Income\n",
    "# Low Values of this ratio will indicate valueable customers\n",
    "# Within the High Value group, we can leverage the model to identify the best targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Tenure_Rank']=pd.qcut(df['tenure'].rank(method='first').values,10,duplicates='drop').codes+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.groupby('Tenure_Rank')['tenure'].agg(['min','max','mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tenure'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Tenure_Segment']=np.where(df['Tenure_Rank']<=6,\"Low Tenure\",\"High Tenure\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['MonthlyCharges_Rank']=pd.qcut(df['MonthlyCharges'].rank(method='first').values,10,duplicates='drop').codes+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.groupby('MonthlyCharges_Rank')['MonthlyCharges'].agg(['min','max','mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['MonthlyCharges'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Monthly_Charge_Segment']=np.where(df['MonthlyCharges_Rank']<=5,\"Low Charges\",\"High Charges\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Predicted_Churn_Rank']=np.where(df['P_Rank_GBM']>=8,\"Top 3\",\"Bottom 7\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slice the data with respect to Top 4 and Bottom 6 Probability Ranks from the GBM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top3=df.loc[df['Predicted_Churn_Rank']=='Top 3',:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service_list=['PhoneService','MultipleLines','InternetService','OnlineSecurity','OnlineBackup','DeviceProtection','TechSupport'\n",
    "              ,'StreamingTV','StreamingMovies','Contract','PaperlessBilling']\n",
    "target=['target']\n",
    "\n",
    "total=service_list+target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top3_services=df_top3[service_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for col in (df_top3_services.columns):\n",
    "    plt.figure()\n",
    "    sns.countplot(x=col,data=df_top3_services)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(index=df_top3['Monthly_Charge_Segment'], columns=df_top3['Tenure_Segment'],values=df_top3['MonthlyCharges'],aggfunc='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(index=df_top3['Monthly_Charge_Segment'], columns=df_top3['Tenure_Segment'],values=df_top3['target'],aggfunc='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recommendations\n",
    "# Device Protection with Online Services\n",
    "# Convert customer to DSL if they are facing challenges with Fiber Optics\n",
    "# Offer discounts on Yearly contracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9dca1b328ad269f30437d24e824e0b1fcc8aba666386700a92f6b78dd67dbb82"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
